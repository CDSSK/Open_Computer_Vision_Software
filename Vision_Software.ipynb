{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eded357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d215cae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\test01\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "import cv2\n",
    "import skimage\n",
    "import mahotas\n",
    "import mahotas.demos\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import tkinter as tk\n",
    "import import_ipynb\n",
    "from skimage import feature\n",
    "\n",
    "from tkinter import *\n",
    "from PIL import ImageFilter\n",
    "from tkinter import filedialog\n",
    "from skimage import filters\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "from torchvision.models.segmentation import FCN_ResNet101_Weights\n",
    "from torchvision.models.segmentation import DeepLabV3_ResNet101_Weights\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "from tkinter import simpledialog\n",
    "from sklearn.decomposition import PCA\n",
    "from tkinter.simpledialog import askinteger\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image as keras_image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "\n",
    "\n",
    "def grayscale(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "\n",
    "    grayimg= cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "    grayimg1= Image.fromarray(grayimg)\n",
    "\n",
    "    grayimg1= ImageTk.PhotoImage(grayimg1)\n",
    "\n",
    "#     panelB = Label(image=grayimg1, borderwidth=5, relief=\"sunken\")\n",
    "#     panelB.image = grayimg1\n",
    "#     panelB.grid(row= 1, column=4 , rowspan= 13,columnspan= 3, padx=20, pady=20)\n",
    "    \n",
    "    image_label = Label(panelB, image=grayimg1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = grayimg1\n",
    "    image_label.place(x=50, y=100)\n",
    "        \n",
    "        \n",
    "    new_img=grayimg\n",
    "\n",
    "    return grayimg\n",
    "\n",
    "def negative(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "    neg= 255 - input_image\n",
    "    neg1= Image.fromarray(neg)\n",
    "\n",
    "    neg1= ImageTk.PhotoImage(neg1)\n",
    "\n",
    "    image_label = Label(panelB, image=neg1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = neg1\n",
    "    image_label.place(x=50, y=100)\n",
    "\n",
    "    new_img=neg\n",
    "\n",
    "    return neg\n",
    "\n",
    "def threshold(input_image, panelB):   #  image = grayscale()\n",
    "    global new_img, image_label\n",
    "    \n",
    "    threshold_value = simpledialog.askinteger(\"Threshold Value\", \"Enter the threshold value:\", initialvalue=127)\n",
    "    if threshold_value is None:\n",
    "        return  # 사용자가 입력 대화 상자를 취소한 경우 아무 작업도 수행하지 않습니다.\n",
    "\n",
    "    gray_image = grayscale(input_image, panelB)\n",
    "\n",
    "    ret, thresh = cv2.threshold(gray_image, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "    thresh1 = Image.fromarray(thresh)\n",
    "    thresh1 = ImageTk.PhotoImage(thresh1)\n",
    "\n",
    "    image_label = Label(panelB, image=thresh1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = thresh1\n",
    "    image_label.place(x=50, y=100)\n",
    " \n",
    "    new_img=thresh\n",
    "\n",
    "    return thresh\n",
    "\n",
    "def redext(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "    row,col,plane = input_image.shape\n",
    "\n",
    "    red = np.zeros((row,col,plane),np.uint8)\n",
    "    red[:,:,0] = input_image[:,:,0]\n",
    "\n",
    "    red1 = Image.fromarray(red)\n",
    "\n",
    "    red1= ImageTk.PhotoImage(red1)\n",
    "\n",
    "    image_label = Label(panelB, image=red1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = red1\n",
    "    image_label.place(x=50, y=100)\n",
    "\n",
    "    new_img=red\n",
    "\n",
    "    return red\n",
    "\n",
    "def greenext(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "    row,col,plane = input_image.shape\n",
    "\n",
    "    green= np.zeros((row,col,plane),np.uint8)\n",
    "    green[:,:,1] = input_image[:,:,1]\n",
    "\n",
    "    green1 = Image.fromarray(green)\n",
    "\n",
    "    green1= ImageTk.PhotoImage(green1)\n",
    "\n",
    "    image_label = Label(panelB, image=green1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = green1\n",
    "    image_label.place(x=50, y=100)\n",
    "\n",
    "    new_img=green\n",
    "\n",
    "    return green\n",
    "\n",
    "def blueext(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "    row,col,plane = input_image.shape\n",
    "\n",
    "    blue = np.zeros((row,col,plane),np.uint8)\n",
    "    blue[:,:,2] = input_image[:,:,2]\n",
    "\n",
    "    blue1 = Image.fromarray(blue)\n",
    "\n",
    "    blue1= ImageTk.PhotoImage(blue1)\n",
    "\n",
    "    image_label = Label(panelB, image=blue1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = blue1\n",
    "    image_label.place(x=50, y=100)\n",
    "    new_img=blue\n",
    "\n",
    "    return blue\n",
    "\n",
    "\n",
    "\n",
    "def edge(input_image, panelB):   # image = threshold(input_image,panelB)\n",
    "    global new_img, image_label\n",
    "\n",
    "    thresholds = simpledialog.askstring(\"Canny Edge Detection\", \"Enter two threshold values separated by a space (e.g., '30 60'):\")\n",
    "    if thresholds is None:\n",
    "        return  # 사용자가 입력 대화 상자를 취소한 경우 아무 작업도 수행하지 않습니다.\n",
    "\n",
    "    low_threshold, high_threshold = map(int, thresholds.split())\n",
    "\n",
    "    edged = cv2.Canny(input_image, low_threshold, high_threshold)\n",
    "    edged1 = Image.fromarray(edged)\n",
    "    edged1 = ImageTk.PhotoImage(edged1)\n",
    "\n",
    "    image_label = Label(panelB, image=edged1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = edged1\n",
    "    image_label.place(x=50, y=100)\n",
    "    \n",
    "    new_img=edged\n",
    "\n",
    "    return edged\n",
    "\n",
    "def skeleton(input_image, panelB):\n",
    "    global new_img, image_label\n",
    "    thr_image = threshold(input_image, panelB)\n",
    "    skel = np.zeros(thr_image.shape, np.uint8)\n",
    "\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))\n",
    "\n",
    "    while True:\n",
    "        open = cv2.morphologyEx(thr_image, cv2.MORPH_OPEN, element)\n",
    "        temp = cv2.subtract(thr_image, open)\n",
    "        eroded = cv2.erode(thr_image, element)\n",
    "        skel = cv2.bitwise_or(skel, temp)\n",
    "        thr_image = eroded.copy()\n",
    "        if cv2.countNonZero(thr_image) == 0:\n",
    "            break\n",
    "\n",
    "    skel1 = Image.fromarray(skel)\n",
    "    skel1 = ImageTk.PhotoImage(skel1)\n",
    "\n",
    "    if image_label is not None:\n",
    "        image_label.destroy()\n",
    "\n",
    "    image_label = Label(panelB, image=skel1, anchor='s')\n",
    "    image_label.image = skel1\n",
    "    image_label.place(x=50, y=100)\n",
    "    new_img = skel\n",
    "\n",
    "    return skel\n",
    "\n",
    "\n",
    "\n",
    "def denoise(input_image, panelB):   # smoothening\n",
    "    global new_img, image_label\n",
    "\n",
    "    # Get visual_patch_size and h from user using simpledialog\n",
    "    visual_patch_size = simpledialog.askinteger(\"Input\", \"Enter visual_patch_size:\", minvalue=1)\n",
    "    h = simpledialog.askfloat(\"Input\", \"Enter h:\", minvalue=1)\n",
    "\n",
    "    # Check if the user canceled the input\n",
    "    if visual_patch_size is None or h is None:\n",
    "        return None\n",
    "\n",
    "    denoise = cv2.fastNlMeansDenoisingColored(input_image, None, int(visual_patch_size), 5, 7, int(h))\n",
    "    denoise1 = Image.fromarray(denoise)\n",
    "\n",
    "    denoise1 = ImageTk.PhotoImage(denoise1)\n",
    "\n",
    "    image_label = Label(panelB, image=denoise1, anchor='s')  \n",
    "    image_label.image = denoise1\n",
    "    image_label.place(x=50, y=100)\n",
    "    \n",
    "    new_img = denoise\n",
    "\n",
    "    return denoise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sharp(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5,-1], [0, -1, 0]])\n",
    "    sharpened = cv2.filter2D(input_image, ddepth=-1, kernel=kernel)\n",
    "\n",
    "    sharpened1 = Image.fromarray(sharpened)\n",
    "\n",
    "    sharpened1= ImageTk.PhotoImage(sharpened1)\n",
    "\n",
    "    image_label = Label(panelB, image=sharpened1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = sharpened1\n",
    "    image_label.place(x=50, y=100)\n",
    "    new_img=sharpened\n",
    "\n",
    "    return sharpened\n",
    "\n",
    "\n",
    "def histo(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "    histogram = cv2.cvtColor(input_image, cv2.COLOR_BGR2YUV)\n",
    "    histogram [:,:,0] = cv2.equalizeHist(histogram [:,:,0])\n",
    "    histogram = cv2.cvtColor(histogram, cv2.COLOR_YUV2BGR)\n",
    "    histogram1 = Image.fromarray(histogram)\n",
    "\n",
    "    histogram1= ImageTk.PhotoImage(histogram1)\n",
    "\n",
    "    image_label = Label(panelB, image=histogram1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = histogram1\n",
    "    image_label.place(x=50, y=100)\n",
    "    new_img=histogram\n",
    "\n",
    "    return histogram\n",
    "\n",
    "\n",
    "def powerlawtrans(input_image, panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "    \n",
    "    # 사용자로부터 감마 값을 입력받음\n",
    "    gamma_value = simpledialog.askfloat(\"Gamma Value\", \"Enter the gamma value:\")\n",
    "    \n",
    "    # 감마 값에 따라 이미지 변환\n",
    "    gammaplt = np.array(255 * (input_image / 255) ** gamma_value, dtype='uint8')\n",
    "    gammaplt1 = Image.fromarray(gammaplt)\n",
    "\n",
    "    gammaplt1 = ImageTk.PhotoImage(gammaplt1)\n",
    "\n",
    "    # 이미지 라벨 생성\n",
    "    image_label = Label(panelB, image=gammaplt1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = gammaplt1\n",
    "    image_label.place(x=50, y=100)\n",
    "    \n",
    "    new_img = gammaplt\n",
    "\n",
    "    return gammaplt\n",
    "\n",
    "\n",
    "def maskimg(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "    x, y , w, h = cv2.selectROI(image)\n",
    "    start = (x, y)\n",
    "    end = (x + w, y + h)\n",
    "    rect = (x, y , w, h)\n",
    "\n",
    "    cv2.rectangle(input_image, start, end, (0,0,255), 3)\n",
    "    mask = np.zeros(input_image.shape[:2], np.uint8)\n",
    "\n",
    "    bgdModel = np.zeros((1, 65), np.float64)\n",
    "    fgdModel = np.zeros((1, 65), np.float64)\n",
    "\n",
    "    cv2.grabCut(input_image, mask, rect, bgdModel, fgdModel, 100, cv2.GC_INIT_WITH_RECT)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    mask1 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "    maskimage = input_image * mask1[:, :, np.newaxis]\n",
    "\n",
    "    maskimage1 = Image.fromarray(maskimage)\n",
    "\n",
    "    maskimage1= ImageTk.PhotoImage(maskimage1)\n",
    "\n",
    "    image_label = Label(panelB, image=maskimage1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = maskimage1\n",
    "    image_label.place(x=50, y=100)\n",
    "    new_img=maskimage\n",
    "\n",
    "    return maskimage\n",
    "\n",
    "def pencil(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "    img=grayscale(input_image,panelB)\n",
    "    img_invert = cv2.bitwise_not(img)\n",
    "    img_smoothing = cv2.GaussianBlur(img_invert, (25, 25),sigmaX=0, sigmaY=0)\n",
    "\n",
    "    pencilimg = cv2.divide(img, 255 - img_smoothing, scale=255)\n",
    "    pencilimg1= Image.fromarray(pencilimg)\n",
    "\n",
    "    pencilimg1= ImageTk.PhotoImage(pencilimg1)\n",
    "\n",
    "    image_label = Label(panelB, image=pencilimg1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = pencilimg1\n",
    "    image_label.place(x=50, y=100)\n",
    "    new_img=pencilimg\n",
    "\n",
    "    return pencilimg\n",
    "\n",
    "def colpencil(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "    img_invert = cv2.bitwise_not(input_image)\n",
    "    img_smoothing = cv2.GaussianBlur(img_invert, (21, 21),sigmaX=0, sigmaY=0)\n",
    "\n",
    "    colpencilimg = cv2.divide(input_image, 255- img_smoothing, scale=255)\n",
    "    colpencilimg1= Image.fromarray(colpencilimg)\n",
    "\n",
    "    colpencilimg1= ImageTk.PhotoImage(colpencilimg1)\n",
    "\n",
    "    image_label = Label(panelB, image=colpencilimg1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = colpencilimg1\n",
    "    image_label.place(x=50, y=100)\n",
    "    new_img=colpencilimg\n",
    "\n",
    "    return colpencilimg\n",
    "\n",
    "def cartoon(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "    gray=grayscale(input_image,panelB)\n",
    "    gray = cv2.medianBlur(gray, 5)\n",
    "    edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 9)\n",
    "\n",
    "    color = cv2.bilateralFilter(input_image, 9, 250, 250)\n",
    "    cartoon = cv2.bitwise_and(color, color, mask=edges)\n",
    "\n",
    "    cartoon1= Image.fromarray(cartoon)\n",
    "\n",
    "    cartoon1= ImageTk.PhotoImage(cartoon1)\n",
    "\n",
    "    image_label = Label(panelB, image=cartoon1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = cartoon1\n",
    "    image_label.place(x=50, y=100)\n",
    "    new_img=cartoon\n",
    "\n",
    "    return cartoon\n",
    "\n",
    "def watercolor(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "    watercolor = cv2.stylization(input_image, sigma_s=100, sigma_r=0.45)\n",
    "\n",
    "    watercolor1= Image.fromarray(watercolor)\n",
    "\n",
    "    watercolor1= ImageTk.PhotoImage(watercolor1)\n",
    "\n",
    "    image_label = Label(panelB, image=watercolor1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = watercolor1\n",
    "    image_label.place(x=50, y=100)\n",
    "    new_img=watercolor\n",
    "\n",
    "    return watercolor\n",
    "\n",
    "def emboss(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "    kernel = np.array([[0,-1,-1],[1,0,-1],[1,1,0]])\n",
    "    emboss = cv2.filter2D(input_image, kernel=kernel, ddepth=-1)\n",
    "    emboss= cv2.cvtColor(emboss, cv2.COLOR_BGR2GRAY)\n",
    "    emboss=255-emboss\n",
    "    emboss1= Image.fromarray(emboss)\n",
    "\n",
    "    emboss1= ImageTk.PhotoImage(emboss1)\n",
    "\n",
    "    image_label = Label(panelB, image=emboss1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = emboss1\n",
    "    image_label.place(x=50, y=100)\n",
    "    new_img=emboss\n",
    "\n",
    "    return emboss\n",
    "\n",
    "def move_image(panelA,panelB):\n",
    "    global image,image_label  # 여기에 image_label 추가\n",
    "    # Get the image from 'Panel B'\n",
    "    img_to_move = image_label.image\n",
    "\n",
    "\n",
    "    image_label_A = Label(panelA, image=img_to_move, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label_A.image = img_to_move\n",
    "    image_label_A.place(x=50, y=100)\n",
    "    \n",
    "    image=new_img\n",
    "    # Clear the image in 'Panel B' by setting an empty image\n",
    "    blank_image = ImageTk.PhotoImage(Image.new('RGB', (500, 500)))\n",
    "    \n",
    "\n",
    "    image_label = Label(panelB, image=blank_image, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = blank_image\n",
    "    image_label.place(x=50, y=100)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def apply_averaging(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "\n",
    "    kernel = np.ones((5,5),np.float32)/25\n",
    "    filtered_image = cv2.filter2D(input_image,-1,kernel)\n",
    "    \n",
    "    filtered_image1= Image.fromarray(filtered_image)\n",
    "\n",
    "    filtered_image1= ImageTk.PhotoImage(filtered_image1)\n",
    "    \n",
    "    \n",
    "    image_label = Label(panelB, image=filtered_image1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = filtered_image1\n",
    "    image_label.place(x=50, y=100)\n",
    "\n",
    "    new_img=filtered_image\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "def apply_gaussian(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "\n",
    "    filtered_image = cv2.GaussianBlur(input_image,(5,5),0)\n",
    "    filtered_image1= Image.fromarray(filtered_image)\n",
    "\n",
    "    filtered_image1= ImageTk.PhotoImage(filtered_image1)\n",
    "    \n",
    "    \n",
    "    image_label = Label(panelB, image=filtered_image1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = filtered_image1\n",
    "    image_label.place(x=50, y=100)\n",
    "\n",
    "    new_img=filtered_image\n",
    "\n",
    "    return filtered_image\n",
    "    \n",
    "def apply_median(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "\n",
    "    filtered_image = cv2.medianBlur(input_image, 5)\n",
    "    filtered_image1= Image.fromarray(filtered_image)\n",
    "\n",
    "    filtered_image1= ImageTk.PhotoImage(filtered_image1)\n",
    "    \n",
    "    \n",
    "    image_label = Label(panelB, image=filtered_image1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = filtered_image1\n",
    "    image_label.place(x=50, y=100)\n",
    "\n",
    "    new_img=filtered_image\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "\n",
    "def apply_bilateral(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "\n",
    "    filtered_image = cv2.bilateralFilter(input_image,9,75,75)\n",
    "    filtered_image1= Image.fromarray(filtered_image)\n",
    "\n",
    "    filtered_image1= ImageTk.PhotoImage(filtered_image1)\n",
    "    \n",
    "    \n",
    "    image_label = Label(panelB, image=filtered_image1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = filtered_image1\n",
    "    image_label.place(x=50, y=100)\n",
    "\n",
    "    \n",
    "    new_img=filtered_image\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "\n",
    "def sift_features(input_image, panelB):\n",
    "    global new_img, image_label\n",
    "\n",
    "    gray = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints = sift.detect(gray, None)\n",
    "    keypoints = sorted(keypoints, key=lambda x: -x.response)[:30]  # 상위 100개의 키포인트만 선택\n",
    "\n",
    "    img_sift = cv2.drawKeypoints(gray, keypoints, input_image)\n",
    "\n",
    "    img_sift1 = Image.fromarray(img_sift)\n",
    "    img_sift1 = ImageTk.PhotoImage(img_sift1)\n",
    "\n",
    "    image_label = Label(panelB, image=img_sift1, anchor='s')\n",
    "    image_label.image = img_sift1\n",
    "    image_label.place(x=50, y=100)\n",
    "\n",
    "    new_img = img_sift\n",
    "\n",
    "    return img_sift\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# def cnn_features(input_image, panelB):\n",
    "#     global new_img, image_label\n",
    "\n",
    "#     # Load the pre-trained VGG-16 model\n",
    "#     model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "#     # Resize and preprocess the image for the VGG-16 model\n",
    "#     img = cv2.resize(input_image, (224, 224))  # Resize to 224x224 pixels\n",
    "#     img = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     x = img_to_array(img)\n",
    "#     x = np.expand_dims(x, axis=0)\n",
    "\n",
    "#     x = preprocess_input(x)\n",
    "\n",
    "#     features = model.predict(x)\n",
    "\n",
    "#     return features\n",
    "\n",
    "\n",
    "\n",
    "def pca_features(input_image, panelB):\n",
    "    global new_img, image_label\n",
    "\n",
    "    n_components = askinteger(\"PCA Component Count\", \"Enter the number of PCA components:\", initialvalue=20)\n",
    "    if n_components is None:\n",
    "        return  # If the user cancels the input, do nothing\n",
    "\n",
    "    blue, green, red = cv2.split(input_image)\n",
    "\n",
    "    pca = PCA(n_components)\n",
    "\n",
    "    # Applying PCA to the red channel and then applying inverse transform to the transformed array.\n",
    "    red_transformed = pca.fit_transform(red)\n",
    "    red_inverted = pca.inverse_transform(red_transformed)\n",
    "\n",
    "    # Applying PCA to the green channel and then applying inverse transform to the transformed array.\n",
    "    green_transformed = pca.fit_transform(green)\n",
    "    green_inverted = pca.inverse_transform(green_transformed)\n",
    "\n",
    "    # Applying PCA to the blue channel and then applying inverse transform to the transformed array.\n",
    "    blue_transformed = pca.fit_transform(blue)\n",
    "    blue_inverted = pca.inverse_transform(blue_transformed)\n",
    "\n",
    "    image_pca_np = np.dstack((red_inverted, red_inverted, red_inverted))\n",
    "    img_compressed = image_pca_np.astype(np.uint8)\n",
    "\n",
    "    pil_image_pca = Image.fromarray(img_compressed)\n",
    "    tk_image_pca = ImageTk.PhotoImage(pil_image_pca)\n",
    "\n",
    "    image_label = Label(panelB, image=tk_image_pca, anchor='s')\n",
    "    image_label.image = tk_image_pca\n",
    "    image_label.place(x=50, y=100)\n",
    "\n",
    "    new_img = image_pca_np\n",
    "\n",
    "    return image_pca_np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lbp_features(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "\n",
    "    gray = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Compute LBP features\n",
    "    lbp = feature.local_binary_pattern(gray, P=24, R=8, method=\"uniform\")\n",
    "\n",
    "    # Normalize the LBP image (for better visualization)\n",
    "    lbp = (lbp - lbp.min()) / (lbp.max() - lbp.min())\n",
    "\n",
    "    img_lbp= Image.fromarray(lbp)\n",
    "    img_lbp1= ImageTk.PhotoImage(img_lbp)\n",
    "\n",
    "    image_label = Label(panelB, image=img_lbp1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = img_lbp1\n",
    "    image_label.place(x=50, y=100)\n",
    "\n",
    "    new_img=lbp\n",
    "\n",
    "    return np.array(lpb)\n",
    "\n",
    "def gabor_features(input_image,panelB):\n",
    "    global new_img, image_label  # 여기에 image_label 추가\n",
    "\n",
    "    # Gabor filter parameters\n",
    "    ksize = 31     # gabor kernel size\n",
    "    sigma = 1.5    # Sigma of the gaussian\n",
    "    theta = np.pi/4   # Orientation angle\n",
    "    lamda = np.pi/4   # Wavelength \n",
    "    gamma = 0.5   # Spatial aspect ratio.\n",
    "\n",
    "    gray_image = cv2.cvtColor(input_image,cv2.COLOR_BGR2GRAY)  \n",
    "\n",
    "    g_kernel = cv2.getGaborKernel((ksize,ksize), sigma, theta, lamda, gamma)\n",
    "\n",
    "    filtered_img=cv2.filter2D(gray_image,cv2.CV_8UC3,g_kernel)\n",
    "\n",
    "    filtered_img1= Image.fromarray(filtered_img)\n",
    "    filtered_img1= ImageTk.PhotoImage(filtered_img1)\n",
    "\n",
    "    image_label = Label(panelB, image=filtered_img1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = filtered_img1\n",
    "    image_label.place(x=50, y=100)\n",
    "\n",
    "    new_img = filtered_img\n",
    "\n",
    "    return filtered_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torchvision.models.segmentation import FCN_ResNet101_Weights\n",
    "from torchvision.models.segmentation import DeepLabV3_ResNet101_Weights\n",
    "\n",
    "\n",
    "fcn_net = models.segmentation.fcn_resnet101(weights=FCN_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1).eval()\n",
    "dlab = models.segmentation.deeplabv3_resnet101(weights=DeepLabV3_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1).eval()\n",
    "\n",
    "def decode_segmap(image, nc=21):  \n",
    "    label_colors = np.array([(i*10%255,i*20%255,i*30%255) for i in range(nc)]) \n",
    "\n",
    "    r,g,b=np.zeros_like(image),np.zeros_like(image),np.zeros_like(image)\n",
    "    \n",
    "    for l in range(1,nc):\n",
    "        idx=image==l\n",
    "        \n",
    "        r[idx]=label_colors[l][2]\n",
    "        g[idx]=label_colors[l][1]\n",
    "        b[idx]=label_colors[l][2]\n",
    "\n",
    "    rgb=np.stack([r,g,b],axis=-1)\n",
    "\n",
    "    return rgb\n",
    "\n",
    "def segment(net,input_image,panelB, show_orig=True, dev='cpu'):\n",
    "    global new_img  # Add this line to declare 'panelB' as a global variable\n",
    "\n",
    "    img = Image.fromarray(input_image)  # Use the global variable image\n",
    "    if show_orig: plt.imshow(img); plt.axis('off'); plt.show() # show_orig=true면 이미지 보여주기\n",
    "  \n",
    "    # T.Resize(640)\n",
    "    trf = T.Compose([T.Resize((500,500)), \n",
    "                     T.ToTensor(), \n",
    "                     T.Normalize(mean = [0.485, 0.456, 0.406], \n",
    "                                 std = [0.229, 0.224, 0.225])])\n",
    "    \n",
    "    inp = trf(img).unsqueeze(0).to(dev)\n",
    "    out = net.to(dev)(inp)['out']\n",
    "    \n",
    "    om = torch.argmax(out.squeeze(), dim=0).detach().cpu().numpy()\n",
    "    \n",
    "    rgb_np=decode_segmap(om)\n",
    "    semantic_tk=ImageTk.PhotoImage(image=Image.fromarray(rgb_np.astype('uint8'), 'RGB'))\n",
    "\n",
    "    image_label = Label(panelB, image=semantic_tk, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = semantic_tk\n",
    "    image_label.place(x=50, y=100)\n",
    "    \n",
    "    new_img=rgb_np\n",
    "    return rgb_np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input as vgg_preprocess_input, decode_predictions as vgg_decode_predictions\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input as resnet_preprocess_input, decode_predictions as resnet_decode_predictions\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input as efficientnet_preprocess_input, decode_predictions as efficientnet_decode_predictions\n",
    "from tensorflow.keras.applications import DenseNet121, MobileNetV2, InceptionV3, Xception\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "\n",
    "\n",
    "\n",
    "# ... (이미지 업로드 및 기타 함수들은 그대로 유지)\n",
    "\n",
    "# Applying DL/ML Methods 서브메뉴에서 VGG16 모델을 사용하여 이미지 분류\n",
    "def apply_vgg_classification():\n",
    "    global image, panelB\n",
    "\n",
    "    # VGG16 모델 불러오기\n",
    "    vgg_model = VGG16(weights='imagenet')\n",
    "\n",
    "    # 이미지 전처리 및 예측\n",
    "    img_array = image.copy()\n",
    "    img_array = cv2.resize(img_array, (224, 224))  # VGG16 모델의 입력 크기에 맞게 조정\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = vgg_preprocess_input(img_array)\n",
    "\n",
    "    predictions = vgg_model.predict(img_array)\n",
    "    decoded_predictions = vgg_decode_predictions(predictions, top=1)[0]\n",
    "\n",
    "    # 결과를 panelB에 표시\n",
    "    result_label = tk.Label(panelB, text=f\"VGG16 Prediction: {decoded_predictions[0][1]}, Confidence: {decoded_predictions[0][2]:.2%}\")\n",
    "    result_label.place(x=20, y=100)\n",
    "    result_label.config(font=(\"Arial\", 14))\n",
    "    result_label.config(bd=2, relief=\"solid\")\n",
    "\n",
    "# Applying DL/ML Methods 서브메뉴에서 ResNet50 모델을 사용하여 이미지 분류\n",
    "def apply_resnet_classification():\n",
    "    global image, panelB\n",
    "\n",
    "    # ResNet50 모델 불러오기\n",
    "    resnet_model = ResNet50(weights='imagenet')\n",
    "\n",
    "    # 이미지 전처리 및 예측\n",
    "    img_array = image.copy()\n",
    "    img_array = cv2.resize(img_array, (224, 224))  # ResNet50 모델의 입력 크기에 맞게 조정\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = resnet_preprocess_input(img_array)\n",
    "\n",
    "    predictions = resnet_model.predict(img_array)\n",
    "    decoded_predictions = resnet_decode_predictions(predictions, top=1)[0]\n",
    "\n",
    "    # 결과를 panelB에 표시\n",
    "    result_label = tk.Label(panelB, text=f\"ResNet50 Prediction: {decoded_predictions[0][1]}, Confidence: {decoded_predictions[0][2]:.2%}\")\n",
    "    result_label.place(x=20, y=180)\n",
    "    result_label.config(font=(\"Arial\", 14))\n",
    "    result_label.config(bd=2, relief=\"solid\")\n",
    "    \n",
    "# Applying DL/ML Methods 서브메뉴에서 EfficientNetB0 모델을 사용하여 이미지 분류\n",
    "def apply_efficientnet_classification():\n",
    "    global image, panelB\n",
    "\n",
    "    # EfficientNetB0 모델 불러오기\n",
    "    efficientnet_model = EfficientNetB0(weights='imagenet')\n",
    "\n",
    "    # 이미지 전처리 및 예측\n",
    "    img_array = image.copy()\n",
    "    img_array = cv2.resize(img_array, (224, 224))  # EfficientNetB0 모델의 입력 크기에 맞게 조정\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = efficientnet_preprocess_input(img_array)\n",
    "\n",
    "    predictions = efficientnet_model.predict(img_array)\n",
    "    decoded_predictions = efficientnet_decode_predictions(predictions, top=1)[0]\n",
    "\n",
    "    # 결과를 panelB에 표시\n",
    "    result_label = tk.Label(panelB, text=f\"EfficientNetB0 Prediction: {decoded_predictions[0][1]}, Confidence: {decoded_predictions[0][2]:.2%}\")\n",
    "    result_label.place(x=20, y=260)\n",
    "    result_label.config(font=(\"Arial\", 14))\n",
    "    result_label.config(bd=2, relief=\"solid\")\n",
    "    \n",
    "    \n",
    "def apply_densenet_classification():\n",
    "    global image, panelB\n",
    "\n",
    "    # DenseNet121 모델 불러오기\n",
    "    densenet_model = DenseNet121(weights='imagenet')\n",
    "\n",
    "    # 이미지 전처리 및 예측\n",
    "    img_array = image.copy()\n",
    "    img_array = cv2.resize(img_array, (224, 224))  # DenseNet121 모델의 입력 크기에 맞게 조정\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "\n",
    "    predictions = densenet_model.predict(img_array)\n",
    "    decoded_predictions = decode_predictions(predictions, top=1)[0]\n",
    "\n",
    "    # 결과를 panelB에 표시하면서 텍스트 위치, 크기, 테두리 설정\n",
    "    result_label = tk.Label(panelB, text=f\"DenseNet121 Prediction: {decoded_predictions[0][1]}, Confidence: {decoded_predictions[0][2]:.2%}\")\n",
    "    result_label.place(x=20, y=340)\n",
    "    result_label.config(font=(\"Arial\", 14))\n",
    "    result_label.config(bd=2, relief=\"solid\")\n",
    "\n",
    "def apply_mobilenetv2_classification():\n",
    "    global image, panelB\n",
    "\n",
    "    # MobileNetV2 모델 불러오기\n",
    "    mobilenetv2_model = MobileNetV2(weights='imagenet')\n",
    "\n",
    "    # 이미지 전처리 및 예측\n",
    "    img_array = image.copy()\n",
    "    img_array = cv2.resize(img_array, (224, 224))  # MobileNetV2 모델의 입력 크기에 맞게 조정\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "\n",
    "    predictions = mobilenetv2_model.predict(img_array)\n",
    "    decoded_predictions = decode_predictions(predictions, top=1)[0]\n",
    "\n",
    "    # 결과를 panelB에 표시하면서 텍스트 위치, 크기, 테두리 설정\n",
    "    result_label = tk.Label(panelB, text=f\"MobileNetV2 Prediction: {decoded_predictions[0][1]}, Confidence: {decoded_predictions[0][2]:.2%}\")\n",
    "    result_label.place(x=20, y=420)\n",
    "    result_label.config(font=(\"Arial\", 14))\n",
    "    result_label.config(bd=2, relief=\"solid\")\n",
    "\n",
    "def apply_inceptionv3_classification():\n",
    "    global image, panelB\n",
    "\n",
    "    # InceptionV3 모델 불러오기\n",
    "    inceptionv3_model = InceptionV3(weights='imagenet')\n",
    "\n",
    "    # 이미지 전처리 및 예측\n",
    "    img_array = image.copy()\n",
    "    img_array = cv2.resize(img_array, (299, 299))  # InceptionV3 모델의 입력 크기에 맞게 조정\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "\n",
    "    predictions = inceptionv3_model.predict(img_array)\n",
    "    decoded_predictions = decode_predictions(predictions, top=1)[0]\n",
    "\n",
    "    # 결과를 panelB에 표시하면서 텍스트 위치, 크기, 테두리 설정\n",
    "    result_label = tk.Label(panelB, text=f\"InceptionV3 Prediction: {decoded_predictions[0][1]}, Confidence: {decoded_predictions[0][2]:.2%}\")\n",
    "    result_label.place(x=20, y=500)\n",
    "    result_label.config(font=(\"Arial\", 14))\n",
    "    result_label.config(bd=2, relief=\"solid\")\n",
    "\n",
    "def apply_xception_classification():\n",
    "    global image, panelB\n",
    "\n",
    "    # Xception 모델 불러오기\n",
    "    xception_model = Xception(weights='imagenet')\n",
    "\n",
    "    # 이미지 전처리 및 예측\n",
    "    img_array = image.copy()\n",
    "    img_array = cv2.resize(img_array, (299, 299))  # Xception 모델의 입력 크기에 맞게 조정\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "\n",
    "    predictions = xception_model.predict(img_array)\n",
    "    decoded_predictions = decode_predictions(predictions, top=1)[0]\n",
    "\n",
    "    # 결과를 panelB에 표시하면서 텍스트 위치, 크기, 테두리 설정\n",
    "    result_label = tk.Label(panelB, text=f\"Xception Prediction: {decoded_predictions[0][1]}, Confidence: {decoded_predictions[0][2]:.2%}\")\n",
    "    result_label.place(x=20, y=580)\n",
    "    result_label.config(font=(\"Arial\", 14))\n",
    "    result_label.config(bd=2, relief=\"solid\")\n",
    "################################함수###############################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaa6a1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam,SGD,RMSprop\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image\n",
    "import threading\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from matplotlib.figure import Figure\n",
    "import tkinter as tk\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "def rename_files_in_folder():\n",
    "    # 사용자에게 폴더 선택하도록 하기\n",
    "    folder_path = filedialog.askdirectory()  # 폴더 하나 선택\n",
    "    if not folder_path:\n",
    "        return\n",
    "    # 폴더 이름을 라벨로 사용\n",
    "    label = os.path.basename(folder_path)\n",
    "    # 폴더 안의 파일 이름 바꾸기\n",
    "    for idx, filename in enumerate(os.listdir(folder_path)):\n",
    "        if filename.endswith(\".png\") or filename.endswith(\".jpg\"):  # 이미지 파일인 경우\n",
    "            dst = label + \"_\" + str(idx) + \".jpg\"\n",
    "            src = folder_path + '/' + filename\n",
    "            dst = folder_path + '/' + dst\n",
    "            os.rename(src, dst)  # 파일 이름 변경\n",
    "            \n",
    "            \n",
    "\n",
    "def distribute_files():\n",
    "    # 사용자에게 폴더 선택하도록 하기\n",
    "    folder_path = filedialog.askdirectory()  # 폴더 하나 선택\n",
    "    if not folder_path:\n",
    "        return\n",
    "\n",
    "    # 선택한 폴더의 상위 폴더 경로 얻기\n",
    "    parent_folder = os.path.dirname(folder_path)\n",
    "\n",
    "    # 상위 폴더에 Train_set, Test_set 폴더 생성\n",
    "    train_folder = os.path.join(parent_folder, 'Train_set')\n",
    "    test_folder = os.path.join(parent_folder, 'Test_set')\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "    # 이미지 파일 리스트 생성\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.endswith('.png') or f.endswith('.jpg')]\n",
    "    random.shuffle(image_files)  # 무작위로 섞기\n",
    "\n",
    "    # 이미지 파일 분배\n",
    "    num_train = int(len(image_files) * 0.7)  # 70%를 훈련 세트로\n",
    "    for i, f in enumerate(image_files):\n",
    "        src = os.path.join(folder_path, f)\n",
    "        # 훈련 세트에 복사\n",
    "        if i < num_train:\n",
    "            dst = os.path.join(train_folder, f)\n",
    "        # 테스트 세트에 복사\n",
    "        else:\n",
    "            dst = os.path.join(test_folder, f)\n",
    "        shutil.copy(src, dst)\n",
    "        \n",
    "        \n",
    "def open_hyperparam_dialog(new_window):\n",
    "    # 새 창 생성\n",
    "    dialog = tk.Toplevel(new_window)\n",
    "\n",
    "    # 각각의 선택 사항에 대한 변수 생성\n",
    "    model_var = tk.StringVar(dialog)\n",
    "    optimizer_var = tk.StringVar(dialog)\n",
    "    lr_var = tk.StringVar(dialog)\n",
    "    epoch_var = tk.StringVar(dialog)\n",
    "\n",
    "    # 각 선택 항목의 라벨 생성 및 배치\n",
    "    model_label = tk.Label(dialog, text='Model')\n",
    "    optimizer_label = tk.Label(dialog, text='Optimizer')\n",
    "    lr_label = tk.Label(dialog, text='Learning Rate')\n",
    "    epoch_label = tk.Label(dialog, text='Epochs')\n",
    "    \n",
    "\n",
    "\n",
    "    # OptionMenu 위젯으로 각각의 선택 사항 표시\n",
    "    model_option = tk.OptionMenu(dialog, model_var, 'VGG16', 'ResNet50', 'InceptionV3')\n",
    "    optimizer_option = tk.OptionMenu(dialog, optimizer_var, 'Adam', 'SGD', 'RMSprop')\n",
    "    lr_option = tk.OptionMenu(dialog, lr_var, '0.1', '0.01', '0.001', '0.0001')\n",
    "    epoch_option = tk.OptionMenu(dialog, epoch_var, '1', '5', '10', '20')\n",
    "\n",
    "    # 위젯 배치\n",
    "    model_label.pack()\n",
    "    model_option.pack()\n",
    "\n",
    "    optimizer_label.pack()\n",
    "    optimizer_option.pack()\n",
    "\n",
    "    lr_label.pack()\n",
    "    lr_option.pack()\n",
    "\n",
    "    epoch_label.pack()\n",
    "    epoch_option.pack()\n",
    "\n",
    "\n",
    "  # 선택한 학습 파라미터를 저장하는 리스트\n",
    "    selected_params = []\n",
    "\n",
    "    # OK 버튼 생성 및 배치. 버튼을 누르면 선택한 값을 저장하고 창을 닫음\n",
    "    ok_button = tk.Button(dialog, text='OK', command=lambda: selected_params.extend([model_var.get(), optimizer_var.get(), lr_var.get(), epoch_var.get()]) or dialog.destroy())\n",
    "    ok_button.pack()\n",
    "\n",
    "    # 창이 닫힐 때까지 대기\n",
    "    dialog.wait_window()\n",
    "\n",
    "    # 선택한 학습 파라미터 반환\n",
    "    return selected_params\n",
    "        \n",
    "\n",
    "def get_model(model_name):\n",
    "    if model_name == 'VGG16':\n",
    "        return VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    elif model_name == 'ResNet50':\n",
    "        return ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    elif model_name == 'InceptionV3':\n",
    "        return InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name\")\n",
    "        \n",
    "def get_optimizer(optimizer, learning_rate):\n",
    "    if optimizer == 'Adam':\n",
    "        return Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        return SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'RMSprop':\n",
    "        return RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid optimizer name\")\n",
    "        \n",
    "\n",
    "def train_model():\n",
    "    model_name, optimizer, learning_rate, epochs = open_hyperparam_dialog(new_window)\n",
    "    base_model = get_model(model_name)\n",
    "\n",
    "    folder_path = filedialog.askdirectory()  # 폴더 선택\n",
    "    if not folder_path:\n",
    "        return\n",
    "\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.endswith('.png') or f.endswith('.jpg')]\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for image_file in image_files:\n",
    "        # 이미지 로드 및 전처리\n",
    "        img = load_img(os.path.join(folder_path, image_file), target_size=(224, 224))\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        X.append(img_array)\n",
    "\n",
    "        # 레이블 추출 및 인코딩\n",
    "        label = image_file.split('_')[0]\n",
    "        y.append(label)\n",
    "    X = np.vstack(X)  # 배열들을 수직으로(열 방향으로) 쌓기\n",
    "\n",
    "    # 레이블 인코딩\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    y = to_categorical(y)\n",
    "\n",
    "    # 데이터 분할\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # 모델 수정\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    predictions = Dense(len(le.classes_), activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # 모델 컴파일\n",
    "    opt = get_optimizer(optimizer, float(learning_rate))\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=int(epochs))\n",
    "    \n",
    "    global trained_model\n",
    "    trained_model=model\n",
    "\n",
    "\n",
    "\n",
    "def test_model(trained_model):\n",
    "    \n",
    "    global y_test_gb, y_pred_classes_gb\n",
    "\n",
    "    folder_path = filedialog.askdirectory()  # 폴더 선택\n",
    "    if not folder_path:\n",
    "        return\n",
    "\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.endswith('.png') or f.endswith('.jpg')]\n",
    "\n",
    "    X_test = []\n",
    "    y_test_gb = []\n",
    "    for image_file in image_files:\n",
    "        # 이미지 로드 및 전처리\n",
    "        img = load_img(os.path.join(folder_path, image_file), target_size=(224, 224))\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        X_test.append(img_array)\n",
    "\n",
    "        # 레이블 추출 및 인코딩\n",
    "        label = image_file.split('_')[0]\n",
    "        y_test_gb.append(label)\n",
    "    X_test = np.vstack(X_test)  # 배열들을 수직으로(열 방향으로) 쌓기\n",
    "    \n",
    "    \n",
    "    # 레이블 인코딩\n",
    "    le = LabelEncoder()\n",
    "    y_test_gb = le.fit_transform(y_test_gb)\n",
    "    \n",
    "    model=trained_model\n",
    "    # 모델 예측\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes_gb = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "\n",
    "def visuallization(y_test_gb, y_pred_classes_gb,new_window):\n",
    "    # 새 창 생성\n",
    "    window = tk.Toplevel(new_window)\n",
    "    canvas = tk.Canvas(window)\n",
    "    scrollbar = tk.Scrollbar(window, command=canvas.yview)\n",
    "    frame = tk.Frame(canvas)\n",
    "    \n",
    "\n",
    "    try:\n",
    "        # 성능 지표 계산\n",
    "        accuracy = accuracy_score(y_test_gb, y_pred_classes_gb)\n",
    "        precision = precision_score(y_test_gb, y_pred_classes_gb, zero_division=0)\n",
    "        recall = recall_score(y_test_gb, y_pred_classes_gb, zero_division=0)\n",
    "        f1 = f1_score(y_test_gb, y_pred_classes_gb, zero_division=0)\n",
    "        roc_auc = roc_auc_score(y_test_gb, y_pred_classes_gb)\n",
    "\n",
    "        # 성능 지표 표시\n",
    "        tk.Label(frame, text=f'Accuracy: {accuracy:.2f}').pack()\n",
    "        tk.Label(frame, text=f'Precision: {precision:.2f}').pack()\n",
    "        tk.Label(frame, text=f'Recall: {recall:.2f}').pack()\n",
    "        tk.Label(frame, text=f'F1 Score: {f1:.2f}').pack()\n",
    "        tk.Label(frame, text=f'ROC AUC: {roc_auc:.2f}').pack()\n",
    "\n",
    "        # ROC Curve 생성\n",
    "        fpr, tpr, _ = roc_curve(y_test_gb, y_pred_classes_gb)\n",
    "        fig1 = Figure(figsize=(5, 5))\n",
    "        a1 = fig1.add_subplot(111)\n",
    "        a1.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "        a1.plot([0, 1], [0, 1], 'k--')\n",
    "        a1.set_xlim([0.0, 1.0])\n",
    "        a1.set_ylim([0.0, 1.05])\n",
    "        a1.set_xlabel('False Positive Rate')\n",
    "        a1.set_ylabel('True Positive Rate')\n",
    "        a1.set_title('Receiver Operating Characteristic')\n",
    "        a1.legend(loc=\"lower right\")\n",
    "        # ROC Curve 표시\n",
    "        canvas1 = FigureCanvasTkAgg(fig1, master=frame)\n",
    "        canvas1.get_tk_widget().pack()\n",
    "    except ValueError:\n",
    "        tk.Label(frame, text='Only one class present in y_true or y_pred. Cannot calculate performance metrics.').pack()\n",
    "\n",
    "    # Confusion Matrix 생성\n",
    "    cm = confusion_matrix(y_test_gb, y_pred_classes_gb)\n",
    "    fig2 = Figure(figsize=(5, 5))\n",
    "    a2 = fig2.add_subplot(111)\n",
    "    cax = a2.matshow(cm)\n",
    "    fig2.colorbar(cax)\n",
    "\n",
    "    # Confusion Matrix 표시\n",
    "    canvas2 = FigureCanvasTkAgg(fig2, master=frame)\n",
    "    canvas2.get_tk_widget().pack()\n",
    "\n",
    "    # 스크롤 바 설정\n",
    "    canvas.create_window((0, 0), window=frame, anchor='nw')\n",
    "    frame.bind(\"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox('all')))\n",
    "    canvas.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "    # 위젯 배치\n",
    "    canvas.pack(side='left', fill='both', expand=True)\n",
    "    scrollbar.pack(side='right', fill='y')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def k_means_clustering(input_image, panelB, k=3):\n",
    "    global new_img, image_label\n",
    "\n",
    "    # Reshape the image to a 2D array of pixels\n",
    "    pixels = input_image.reshape((-1, 3))\n",
    "\n",
    "    # Perform k-means clustering\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(pixels)\n",
    "\n",
    "    # Assign each pixel to a cluster\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # Replace each pixel with its corresponding centroid\n",
    "    segmented_image = kmeans.cluster_centers_.astype(int)[labels]\n",
    "\n",
    "    # Reshape the segmented image back to its original shape\n",
    "    segmented_image = segmented_image.reshape(input_image.shape)\n",
    "\n",
    "    # Convert to uint8\n",
    "    segmented_image = segmented_image.astype(np.uint8)\n",
    "\n",
    "    # Display the segmented image in panelB\n",
    "    segmented_img = Image.fromarray(segmented_image)\n",
    "    segmented_img = ImageTk.PhotoImage(segmented_img)\n",
    "\n",
    "    image_label = Label(panelB, image=segmented_img, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = segmented_img\n",
    "    image_label.place(x=50, y=100)\n",
    "\n",
    "    new_img = segmented_image\n",
    "\n",
    "    return segmented_image\n",
    "\n",
    "\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "image_label = None  # Declare image_label as a global variable\n",
    "def mean_shift_clustering(input_image, panelB):\n",
    "    global new_img, image_label\n",
    "\n",
    "    # Reshape the image to a 2D array of pixels\n",
    "    pixels = input_image.reshape((-1, 3))\n",
    "\n",
    "    # Estimate bandwidth for mean shift\n",
    "    bandwidth = estimate_bandwidth(pixels, quantile=0.2, n_samples=500)\n",
    "\n",
    "    # Perform mean shift clustering\n",
    "    ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    ms.fit(pixels)\n",
    "\n",
    "    # Assign each pixel to a cluster\n",
    "    labels = ms.labels_\n",
    "\n",
    "    # Replace each pixel with its corresponding centroid\n",
    "    segmented_image = ms.cluster_centers_.astype(int)[labels]\n",
    "\n",
    "    # Reshape the segmented image back to its original shape\n",
    "    segmented_image = segmented_image.reshape(input_image.shape)\n",
    "\n",
    "    # Convert to uint8\n",
    "    segmented_image = segmented_image.astype(np.uint8)\n",
    "\n",
    "    # Display the segmented image in panelB\n",
    "    segmented_img = Image.fromarray(segmented_image)\n",
    "    segmented_img = ImageTk.PhotoImage(segmented_img)\n",
    "\n",
    "    if image_label is not None:\n",
    "        image_label.destroy()  # Remove previous image label in panelB\n",
    "\n",
    "    image_label = Label(panelB, image=segmented_img, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label.image = segmented_img\n",
    "    image_label.place(x=50, y=100)\n",
    "\n",
    "    new_img = segmented_image\n",
    "\n",
    "    return segmented_image\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65d6e78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The specified image file was not found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_menu_button(parent, label, command=None):\n",
    "    button = tk.Menubutton(parent, text=label, relief=\"raised\")\n",
    "    menu = tk.Menu(button)\n",
    "    button.config(menu=menu)\n",
    "    menu.add_command(label=label, command=command)\n",
    "    return button\n",
    "\n",
    "\n",
    "\n",
    "def upload_image():\n",
    "    global image, image_label_A, panelB\n",
    "    f_types = [('PNG 파일', '*.png'), ('Jpg 파일', '*.jpg')]\n",
    "    path = filedialog.askopenfilename(filetypes=f_types)\n",
    "    \n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, (500, 500))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image1 = Image.fromarray(image)\n",
    "    image1 = ImageTk.PhotoImage(image1)\n",
    "\n",
    "    # 새 이미지를 panelA에 표시\n",
    "    image_label_A = tk.Label(panelA, image=image1, anchor='s')  # 's'는 하단 정렬을 의미\n",
    "    image_label_A.image = image1\n",
    "    image_label_A.place(x=50, y=100)\n",
    "    \n",
    "    panelB = tk.Frame(new_window, background='white', width=50, height=10)\n",
    "    panelB.grid(row=0, column=2, sticky='nsew')\n",
    "\n",
    "    return image\n",
    "    \n",
    "\n",
    "\n",
    "def clear_panels():\n",
    "    global image_label_A, image_label, image, panelA, panelB   # 이미지 레이블 변수를 가져옴\n",
    "    if image_label_A is not None:\n",
    "        image_label_A.destroy()  # panelA에 있는 이미지 레이블 제거\n",
    "    if image_label is not None:\n",
    "        image_label.destroy()  # panelB에 있는 이미지 레이블 제거\n",
    "    # panelA와 panelB를 완전히 초기화하려면 새로운 빈 프레임을 생성\n",
    "    panelA = tk.Frame(new_window, background='white', width=50, height=10)\n",
    "    panelB = tk.Frame(new_window, background='white', width=50, height=10)\n",
    "    panelA.grid(row=0, column=1, sticky='nsew')\n",
    "    panelB.grid(row=0, column=2, sticky='nsew')\n",
    "    panelA.pack_propagate(0)  # panelA의 크기를 고정\n",
    "\n",
    "\n",
    "def show_analysis():\n",
    "    global new_window, image_label_A\n",
    "    root.destroy()\n",
    "\n",
    "    new_window = tk.Tk()\n",
    "\n",
    "    panelS = tk.Frame(new_window, background='#DC143C', width=10, height=10)\n",
    "    global panelA,panelB\n",
    "    panelA = tk.Frame(new_window, background='white',width=50, height=10)\n",
    "    panelB = tk.Frame(new_window,  background='white',width=50, height=10)\n",
    "\n",
    "    panelS.grid(row=0, column=0, sticky='nsew')\n",
    "    panelA.grid(row=0, column=1, sticky='nsew')\n",
    "    panelB.grid(row=0, column=2, sticky='nsew')\n",
    "\n",
    "    panelA.pack_propagate(0)  # panelA의 크기를 고정\n",
    "\n",
    "    create_menu(new_window)\n",
    "\n",
    "    new_window.grid_rowconfigure(0, weight=1)\n",
    "    new_window.grid_columnconfigure(0, weight=1)\n",
    "    new_window.grid_columnconfigure(1, weight=15)\n",
    "    new_window.grid_columnconfigure(2, weight=15)\n",
    "    \n",
    "\n",
    "    button_labels = ['Inputting Image Data',  'Preprocessing','Filtering','Correction','Transformation', 'Feature Extraction',\n",
    "                     'Segmentation', 'Clustering',\n",
    "                     'Transfer Learning', 'Training Model', 'Updating an Image', 'Clear Panels']\n",
    "\n",
    "    \n",
    "# panelS의 가로 폭 설정\n",
    "    panelS.grid_columnconfigure(0, weight=1)\n",
    "\n",
    "    for i, name in enumerate(button_labels):\n",
    "    # Create a Menubutton\n",
    "        mbt = tk.Menubutton(panelS, text=name, height=2, font=(\"Arial\", 13,\"bold\"), relief='raised')\n",
    "        mbt.grid(row=i, sticky=\"ew\")  # sticky 옵션을 사용하여 가로 크기를 패널의 가로 폭에 맞게 설정\n",
    "        \n",
    "        \n",
    "        if name == 'Inputting Image Data':\n",
    "            mbt.configure(highlightthickness=1, highlightbackground=\"crimson\", highlightcolor=\"crimson\",font=('Arial',12,\"italic\"))\n",
    "        elif name == 'Updating an Image':\n",
    "            mbt.configure(highlightthickness=1, highlightbackground=\"crimson\", highlightcolor=\"crimson\",font=('Arial',12,\"italic\"))\n",
    "        elif name == 'Clear Panels':\n",
    "            mbt.configure(highlightthickness=1, highlightbackground=\"crimson\", highlightcolor=\"crimson\",font=('Arial',12,\"italic\"))\n",
    "        else:\n",
    "            mbt.configure(highlightthickness=1, highlightbackground=\"crimson\", highlightcolor=\"crimson\")\n",
    " \n",
    "        # Create a Menu for the Menubutton\n",
    "        mnu = tk.Menu(mbt)\n",
    "\n",
    "\n",
    "        if name == 'Inputting Image Data':\n",
    "            mnu.add_command(label='Upload', command=upload_image)\n",
    "\n",
    "\n",
    "        elif name == 'Preprocessing':\n",
    "            mnu.add_command(label='Grayscale', command=lambda: grayscale(image, panelB))\n",
    "            mnu.add_command(label='Invert Color', command=lambda: negative(image, panelB))\n",
    "            mnu.add_command(label='Red Attribute', command=lambda: redext(image, panelB))\n",
    "            mnu.add_command(label='Green Attribute', command=lambda: greenext(image, panelB))\n",
    "            mnu.add_command(label='Blue Attribute', command=lambda: blueext(image, panelB))\n",
    "            \n",
    "            \n",
    "        elif name == 'Filtering':\n",
    "            mnu.add_command(label='Averaging Blur', command=lambda: apply_averaging(image, panelB))\n",
    "            mnu.add_command(label='Gaussian Blur', command=lambda: apply_gaussian(image, panelB))\n",
    "            mnu.add_command(label='Median Blur', command=lambda: apply_median(image, panelB))\n",
    "            mnu.add_command(label='Bilateral Blur', command=lambda: apply_bilateral(image, panelB))\n",
    "            mnu.add_command(label='Sharpening', command=lambda: sharp(image, panelB))\n",
    "            mnu.add_command(label='Smoothening', command=lambda: denoise(image, panelB))\n",
    "\n",
    "\n",
    "        elif name == 'Correction':\n",
    "            mnu.add_command(label='Binary', command=lambda: threshold(image, panelB))\n",
    "            mnu.add_command(label='Edge Detection', command=lambda: edge(image, panelB))\n",
    "            mnu.add_command(label='Skeleton', command=lambda: skeleton(image, panelB))\n",
    "            mnu.add_command(label='Power Law Transformation', command=lambda: powerlawtrans(image, panelB))\n",
    "            mnu.add_command(label='Contrast Enhancement', command=lambda: histo(image, panelB))\n",
    "\n",
    "\n",
    "\n",
    "        elif name == 'Transformation':\n",
    "            mnu.add_command(label='Pencil Sketch', command=lambda: pencil(image, panelB))\n",
    "            mnu.add_command(label='Color Pencil Sketch', command=lambda: colpencil(image, panelB))\n",
    "            mnu.add_command(label='Cartoonify', command=lambda: cartoon(image, panelB))\n",
    "            mnu.add_command(label='Watercolor', command=lambda: watercolor(image, panelB))\n",
    "            mnu.add_command(label='Emboss', command=lambda: emboss(image, panelB))\n",
    "\n",
    "        elif name == 'Feature Extraction':\n",
    "            mnu.add_command(label='SIFT', command=lambda:sift_features(image,panelB))\n",
    "            #mnu.add_command(label='**CNN(VGG16)', command=lambda:cnn_features(image,panelB))\n",
    "            mnu.add_command(label='PCA', command=lambda:pca_features(image,panelB))\n",
    "            ##mnu.add_command(label='**LBP', command=lambda:lbp_features(image,panelB))\n",
    "            mnu.add_command(label='Gabor', command=lambda:gabor_features(image,panelB))\n",
    "\n",
    "            \n",
    "        elif name == 'Segmentation':\n",
    "            mnu.add_command(label='Semantic(FCN)', command=lambda: segment(fcn_net,image,panelB))\n",
    "            mnu.add_command(label='Semantic(DLAB)', command=lambda: segment(dlab,image,panelB))\n",
    "            \n",
    "            \n",
    "        elif name =='Transfer Learning':   \n",
    "            mnu.add_command(label='VGG16', command=apply_vgg_classification)\n",
    "            mnu.add_command(label='ResNet50', command=apply_resnet_classification)\n",
    "            mnu.add_command(label='EfficientNetB0', command=apply_efficientnet_classification)\n",
    "            mnu.add_command(label='DenseNet121', command=apply_densenet_classification)\n",
    "            mnu.add_command(label='MobileNetV2', command=apply_mobilenetv2_classification)\n",
    "            mnu.add_command(label='InceptionV3', command=apply_inceptionv3_classification)\n",
    "            mnu.add_command(label='Xception', command=apply_xception_classification)\n",
    "            \n",
    "        elif name == 'Clustering':\n",
    "            mnu.add_command(label='K-means clustering', command=lambda: k_means_clustering(image,panelB))\n",
    "            mnu.add_command(label='mean shift clustering', command=lambda: mean_shift_clustering(image,panelB))\n",
    "\n",
    "            \n",
    "        elif name =='Updating an Image':\n",
    "            mnu.add_command(label='Apply Image to Source Image', command=lambda:move_image(panelA,panelB))\n",
    "        \n",
    "        elif name == 'Clear Panels':\n",
    "            mnu.add_command(label='Clear Panels', command=clear_panels)\n",
    "            \n",
    "        elif name == 'Training Model':\n",
    "            mnu.add_command(label='1.Rename Images', command=rename_files_in_folder)\n",
    "            mnu.add_command(label='2.Make Train/Test Files', command=distribute_files)\n",
    "            mnu.add_command(label='3.Train Model', command=train_model)\n",
    "            mnu.add_command(label='4.Test Model', command=lambda:test_model(trained_model))\n",
    "            mnu.add_command(label='5.Result', command=lambda:visuallization(y_test_gb, y_pred_classes_gb,new_window))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        # Attach the menu to the Menubutton\n",
    "\n",
    "        else:\n",
    "            for j in range(5):  # Add five options to the menu as an example.\n",
    "                mnu.add_command(label=f'Sub Button {j+1}')\n",
    "\n",
    "        # Attach the menu to the Menubutton\n",
    "        mbt.configure(menu=mnu)\n",
    "\n",
    "\n",
    "    \n",
    "def create_menu(parent):\n",
    "    parent.title('Analysis')\n",
    "\n",
    "    menubar = tk.Menu(parent)\n",
    "\n",
    "    parent.geometry(\"1800x900\")\n",
    "\n",
    "    filemenu = tk.Menu(menubar, tearoff=0)\n",
    "    filemenu.add_command(label=\"Open\")\n",
    "    filemenu.add_command(label=\"Save\")\n",
    "    menubar.add_cascade(label=\"File\", menu=filemenu)\n",
    "\n",
    "    editmenu = tk.Menu(menubar, tearoff=0)\n",
    "    editmenu.add_command(label=\"Undo\")\n",
    "    menubar.add_cascade(label=\"Edit\", menu=editmenu)\n",
    "\n",
    "    viewmenu = tk.Menu(menubar, tearoff=0)\n",
    "    viewmenu.add_command(label=\"Zoom In\")\n",
    "    menubar.add_cascade(label=\"View\", menu=viewmenu)\n",
    "\n",
    "    option_menu = tk.Menu(menubar)\n",
    "    option_menu.add_command(label='Settings')\n",
    "    menubar.add_cascade(menu=option_menu, label='Options')\n",
    "\n",
    "    help_menu = tk.Menu(menubar)\n",
    "    menubar.add_cascade(menu=help_menu, label='Help')\n",
    "\n",
    "    new_window.config(menu=menubar)\n",
    "\n",
    "\n",
    "    \n",
    "def show_main():\n",
    "    analysis_button = create_button(root,\"ANALYSIS\", 1) \n",
    "    analysis_button.config(command=show_analysis,\n",
    "                           fg=\"white\",\n",
    "                           width=15,\n",
    "                           bg=\"crimson\",\n",
    "                           activebackground=\"crimson\",\n",
    "                           font=(\"Helvetica\", 17, \"bold\"))\n",
    "\n",
    "    \n",
    "    cds_lab_button = create_button(root,\"CDS LAB\", 2)\n",
    "\n",
    "    model_button = create_button(root,\"MODEL\", 3)\n",
    "\n",
    "    function_button = create_button(root,\"FUNCTION\", 4)\n",
    "    \n",
    "    \n",
    "    \n",
    "def create_button(parent, text, row):\n",
    "    button = tk.Button(parent, text=text, width=25, fg=\"crimson\", bg=\"white\", activebackground=\"crimson\", font=(\"Helvetica\", 10, \"bold\"))\n",
    "    button.grid(row=row, column=0)\n",
    "    return button\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title('Cloud Alpha')\n",
    "\n",
    "\n",
    "# 창의 시작 크기 설정 (예: 300x200)\n",
    "root.geometry(\"800x600\")\n",
    "\n",
    "# 화면 해상도\n",
    "screen_width = root.winfo_screenwidth()\n",
    "screen_height = root.winfo_screenheight()\n",
    "\n",
    "# update_idletasks() 함수를 호출하여 변경 사항을 즉시 반영\n",
    "root.update_idletasks()\n",
    "\n",
    "# Tkinter 창의 실제 크기\n",
    "window_width = root.winfo_width()\n",
    "window_height = root.winfo_height()\n",
    "\n",
    "# 중앙에 위치시킬 때의 좌표 계산\n",
    "position_top = int(screen_height / 2 - window_height / 2)\n",
    "position_right = int(screen_width / 2 - window_width / 2)\n",
    "\n",
    "# 창의 위치 설정\n",
    "root.geometry(\"+{}+{}\".format(position_right, position_top))\n",
    "\n",
    "\n",
    "# 전역 변수로 선언\n",
    "img = None\n",
    "imgtk = None\n",
    "\n",
    "try:\n",
    "   # 이미지 로드 (여기서는 example.png라는 이름의 파일을 사용합니다.)\n",
    "    img = Image.open(\"C:\\\\Users\\\\user\\\\Desktop\\\\project\\\\image\\\\korea.png\") \n",
    "    img = img.resize((250, 250)) # 이미지 크기 조정\n",
    "    imgtk = ImageTk.PhotoImage(img)\n",
    "\n",
    "    # grid 설정\n",
    "    root.grid_rowconfigure(0, weight=1)\n",
    "    root.grid_rowconfigure(1, weight=3)  # 비율을 조정하여 이미지를 상단으로 이동시킵니다.\n",
    "    root.grid_columnconfigure(0, weight=1)\n",
    "\n",
    "    # 레이블 위젯 생성 후 이미지 설정\n",
    "    label_img = tk.Label(root, image=imgtk)\n",
    "    label_img.grid(row=0, column=0)\n",
    "    \n",
    "    \n",
    "except FileNotFoundError: \n",
    "    print(\"The specified image file was not found.\") \n",
    "    \n",
    "show_main()\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc21dfed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b18905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9e7379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f341b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
